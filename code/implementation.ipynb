{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6XKss536PUVf"
      },
      "id": "6XKss536PUVf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Cornell/CS5782"
      ],
      "metadata": {
        "id": "x_MKiBsbPXDh"
      },
      "id": "x_MKiBsbPXDh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8f83b48a",
      "metadata": {
        "id": "8f83b48a",
        "outputId": "8552919c-fe11-427a-e875-0b47534cddaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for docopt (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Cloning into '5782_Final_Project'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 71 (delta 12), reused 63 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (71/71), 35.43 KiB | 5.06 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "/content/5782_Final_Project/code\n"
          ]
        }
      ],
      "source": [
        "# Implementation script for Arithmetic Transformer\n",
        "# This script will be converted to a notebook for Google Colab\n",
        "\n",
        "# Cell 1: Setup and Installation\n",
        "\"\"\"\n",
        "# Investigating the Limitations of Transformers with Simple Arithmetic Tasks\n",
        "\n",
        "This notebook implements the experiments from the paper:\n",
        "[Nogueira, Jiang, Lin \"Investigating the Limitations of Transformers with Simple Arithmetic Tasks\", 2021](https://arxiv.org/abs/2102.13019)\n",
        "\n",
        "It demonstrates how different number representations affect the ability of transformer models to learn arithmetic tasks.\n",
        "\n",
        "## Setup\n",
        "First, let's install the required packages and set up the environment.\n",
        "\"\"\"\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q torch pytorch-lightning transformers num2words numpy pandas matplotlib tqdm\n",
        "\n",
        "# Clone the repository if running on Colab\n",
        "!if [ ! -d \"5782_Final_Project\" ]; then git clone https://github.com/joshiarnav/5782_Final_Project.git; fi\n",
        "\n",
        "# Navigate to the code directory\n",
        "%cd 5782_Final_Project/code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "212d930a",
      "metadata": {
        "id": "212d930a"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Import Libraries and Set Parameters\n",
        "\"\"\"\n",
        "## Configuration\n",
        "Let's set up the configuration for training the model.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 1\n",
        "random.seed(SEED)\n",
        "pl.seed_everything(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Define training parameters\n",
        "OUTPUT_DIR = './output'\n",
        "MODEL_NAME = 't5-base'\n",
        "OPERATION = 'addition'  # 'addition' or 'subtraction'\n",
        "ORTHOGRAPHY = '10ebased'  # 'decimal', 'character', 'character_fixed', 'underscore', 'words', '10based', '10ebased'\n",
        "MAX_DIGITS_TRAIN = 5  # Reduced from 15 for faster training\n",
        "MAX_DIGITS_TEST = 5   # Reduced from 15 for faster training\n",
        "TRAIN_SIZE = 1000      # Reduced from 100000 for faster training\n",
        "VAL_SIZE = 200         # Reduced from 10000 for faster training\n",
        "TEST_SIZE = 200        # Reduced from 10000 for faster training\n",
        "BATCH_SIZE = 4\n",
        "MAX_EPOCHS = 5         # Reduced from 20 for faster training\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5774ab59",
      "metadata": {
        "id": "5774ab59"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Run Training\n",
        "\"\"\"\n",
        "## Training\n",
        "Now let's train the model using the specified parameters.\n",
        "\"\"\"\n",
        "\n",
        "# Construct the training command\n",
        "train_command = f\"\"\"python train.py \\\n",
        "    --output_dir={OUTPUT_DIR} \\\n",
        "    --model_name_or_path={MODEL_NAME} \\\n",
        "    --operation={OPERATION} \\\n",
        "    --orthography={ORTHOGRAPHY} \\\n",
        "    --balance_train \\\n",
        "    --balance_val \\\n",
        "    --train_size={TRAIN_SIZE} \\\n",
        "    --val_size={VAL_SIZE} \\\n",
        "    --test_size={TEST_SIZE} \\\n",
        "    --min_digits_train=2 \\\n",
        "    --max_digits_train={MAX_DIGITS_TRAIN} \\\n",
        "    --min_digits_test=2 \\\n",
        "    --max_digits_test={MAX_DIGITS_TEST} \\\n",
        "    --base_number=10 \\\n",
        "    --seed={SEED} \\\n",
        "    --train_batch_size={BATCH_SIZE} \\\n",
        "    --accumulate_grad_batches=4 \\\n",
        "    --val_batch_size={BATCH_SIZE*4} \\\n",
        "    --max_seq_length=512 \\\n",
        "    --num_workers=2 \\\n",
        "    --optimizer=AdamW \\\n",
        "    --lr=3e-4 \\\n",
        "    --weight_decay=5e-5 \\\n",
        "    --scheduler=StepLR \\\n",
        "    --gamma=1.0 \\\n",
        "    --step_size=1000 \\\n",
        "    --max_epochs={MAX_EPOCHS} \\\n",
        "    --check_val_every_n_epoch=1 \\\n",
        "    --precision=32 \\\n",
        "    --gradient_clip_val=1.0\"\"\"\n",
        "\n",
        "# Execute the training command\n",
        "!{train_command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1affbb14",
      "metadata": {
        "id": "1affbb14"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Evaluate Results\n",
        "\"\"\"\n",
        "## Results\n",
        "Let's evaluate the results of our training.\n",
        "\"\"\"\n",
        "\n",
        "# Load results\n",
        "results_file = os.path.join(OUTPUT_DIR, 'results.json')\n",
        "if os.path.exists(results_file):\n",
        "    with open(results_file, 'r') as f:\n",
        "        results = json.load(f)\n",
        "    print(f\"Test Exact Match: {results['test_exact_match']:.4f}\")\n",
        "\n",
        "    # Display other metadata\n",
        "    print(f\"Operation: {results['operation']}\")\n",
        "    print(f\"Orthography: {results['orthography']}\")\n",
        "    print(f\"Max Digits (Train): {results['max_digits_train']}\")\n",
        "    print(f\"Max Digits (Test): {results['max_digits_test']}\")\n",
        "else:\n",
        "    print(\"No results file found. Training may have failed or is still in progress.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddfb8080",
      "metadata": {
        "id": "ddfb8080"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Visualize Sample Predictions\n",
        "\"\"\"\n",
        "## Sample Predictions\n",
        "Let's look at some sample predictions from the model.\n",
        "\"\"\"\n",
        "\n",
        "# Find the latest log file\n",
        "log_files = glob.glob(os.path.join(OUTPUT_DIR, 'logs', '*.txt'))\n",
        "if log_files:\n",
        "    latest_log = max(log_files, key=os.path.getmtime)\n",
        "    print(f\"Latest log file: {latest_log}\")\n",
        "\n",
        "    # Extract and display sample predictions\n",
        "    samples = []\n",
        "    current_sample = {}\n",
        "    with open(latest_log, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        for i, line in enumerate(lines):\n",
        "            if 'Sample question:' in line:\n",
        "                if current_sample and 'question' in current_sample:\n",
        "                    samples.append(current_sample)\n",
        "                current_sample = {}\n",
        "                current_sample['question'] = line.split('Sample question:')[1].strip()\n",
        "            elif 'Sample correct answer:' in line and 'question' in current_sample:\n",
        "                current_sample['correct'] = line.split('Sample correct answer:')[1].strip()\n",
        "            elif 'Sample predicted answer:' in line and 'question' in current_sample:\n",
        "                current_sample['predicted'] = line.split('Sample predicted answer:')[1].strip()\n",
        "            elif 'Exact match:' in line and 'question' in current_sample:\n",
        "                current_sample['exact_match'] = line.split('Exact match:')[1].strip()\n",
        "\n",
        "    # Add the last sample if it exists\n",
        "    if current_sample and 'question' in current_sample:\n",
        "        samples.append(current_sample)\n",
        "\n",
        "    # Display samples\n",
        "    for i, sample in enumerate(samples[:5]):  # Show up to 5 samples\n",
        "        print(f\"\\nSample {i+1}:\")\n",
        "        print(f\"Question: {sample.get('question', 'N/A')}\")\n",
        "        print(f\"Correct: {sample.get('correct', 'N/A')}\")\n",
        "        print(f\"Predicted: {sample.get('predicted', 'N/A')}\")\n",
        "        print(f\"Exact Match: {sample.get('exact_match', 'N/A')}\")\n",
        "else:\n",
        "    print(\"No log files found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea9293d9",
      "metadata": {
        "id": "ea9293d9"
      },
      "outputs": [],
      "source": [
        "# Cell 6: Visualize Performance Across Different Orthographies\n",
        "\"\"\"\n",
        "## Orthography Comparison\n",
        "Let's visualize how different number representations (orthographies) affect model performance.\n",
        "\"\"\"\n",
        "\n",
        "# This is a placeholder for actual data - in a real scenario, you would run multiple experiments\n",
        "# with different orthographies and collect the results\n",
        "orthographies = ['decimal', 'character', 'character_fixed', 'underscore', 'words', '10based', '10ebased']\n",
        "accuracies = [0.05, 0.35, 0.45, 0.40, 0.60, 0.95, 0.98]  # Placeholder data based on paper findings\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(orthographies, accuracies, color='skyblue')\n",
        "plt.xlabel('Number Representation', fontsize=12)\n",
        "plt.ylabel('Accuracy (Exact Match)', fontsize=12)\n",
        "plt.title('Model Performance by Number Representation', fontsize=14)\n",
        "plt.ylim(0, 1.0)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Add a horizontal line at 0.5 for reference\n",
        "plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43413395",
      "metadata": {
        "id": "43413395"
      },
      "outputs": [],
      "source": [
        "# Cell 7: Evaluate Custom Examples\n",
        "\"\"\"\n",
        "## Custom Evaluation\n",
        "Let's evaluate the model on some custom examples.\n",
        "\"\"\"\n",
        "\n",
        "# Find the latest checkpoint\n",
        "checkpoint_files = glob.glob(os.path.join(OUTPUT_DIR, '*.ckpt'))\n",
        "if checkpoint_files:\n",
        "    latest_checkpoint = max(checkpoint_files, key=os.path.getmtime)\n",
        "    print(f\"Latest checkpoint: {latest_checkpoint}\")\n",
        "\n",
        "    # Construct the evaluation command\n",
        "    examples = [\"123,456\", \"7890,1234\", \"9999,9999\"]\n",
        "    eval_command = f\"python evaluate.py \\\n",
        "        --checkpoint_dir={OUTPUT_DIR} \\\n",
        "        --operation={OPERATION} \\\n",
        "        --orthography={ORTHOGRAPHY} \\\n",
        "        --max_digits={MAX_DIGITS_TEST} \\\n",
        "        --examples {' '.join(examples)}\"\n",
        "\n",
        "    # Execute the evaluation command\n",
        "    !{eval_command}\n",
        "else:\n",
        "    print(\"No checkpoint files found.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V6E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}